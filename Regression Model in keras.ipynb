{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download an clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('concrete_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop(['Strength'], axis =1)\n",
    "target = df['Strength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551341  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors-predictors.mean())/predictors.std()\n",
    "predictors_norm.astype('float32').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train, Y_test = train_test_split(predictors_norm, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape= (8,)))\n",
    "\n",
    "model.compile(optimizer='adam', loss ='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 2s 50ms/step - loss: 1520.5920 - val_loss: 1509.4630\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1554.1972 - val_loss: 1506.9702\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1550.6983 - val_loss: 1504.4320\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1582.0180 - val_loss: 1501.8292\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1513.4331 - val_loss: 1499.2655\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1505.6367 - val_loss: 1496.6086\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1519.1231 - val_loss: 1493.9562\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1502.9991 - val_loss: 1491.3220\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1507.6754 - val_loss: 1488.7090\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1550.4427 - val_loss: 1486.0239\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1470.0703 - val_loss: 1483.3871\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1488.8105 - val_loss: 1480.6848\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1479.5017 - val_loss: 1477.9734\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1543.5556 - val_loss: 1475.2498\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1531.0944 - val_loss: 1472.5317\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1520.3924 - val_loss: 1469.8623\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1482.5962 - val_loss: 1467.1093\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1521.4960 - val_loss: 1464.4332\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.5044 - val_loss: 1461.6565\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1494.2986 - val_loss: 1458.9160\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1494.5804 - val_loss: 1456.1027\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1494.1304 - val_loss: 1453.3971\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1520.2974 - val_loss: 1450.5039\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1429.2301 - val_loss: 1447.8517\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1487.4952 - val_loss: 1445.0958\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1463.6990 - val_loss: 1442.2963\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1472.4082 - val_loss: 1439.4540\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1466.0758 - val_loss: 1436.7014\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1475.2500 - val_loss: 1433.9205\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1447.0697 - val_loss: 1431.2275\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1439.6455 - val_loss: 1428.4462\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1510.9560 - val_loss: 1425.6377\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1411.1182 - val_loss: 1422.9716\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1475.7497 - val_loss: 1420.1652\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1429.6423 - val_loss: 1417.4193\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.4305 - val_loss: 1414.6257\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1484.1624 - val_loss: 1411.8732\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1397.7655 - val_loss: 1409.1530\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1477.1334 - val_loss: 1406.3938\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1419.6423 - val_loss: 1403.7076\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1379.0227 - val_loss: 1400.9814\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1400.2140 - val_loss: 1398.2836\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1429.5271 - val_loss: 1395.5565\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.4744 - val_loss: 1392.8385\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1456.7082 - val_loss: 1390.0726\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1426.6251 - val_loss: 1387.4120\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1351.5233 - val_loss: 1384.7170\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1488.0235 - val_loss: 1382.0792\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1408.3094 - val_loss: 1379.3936\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1460.1076 - val_loss: 1376.7599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d4c89e250>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs= 50, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean squared errors = 1460.1076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  epochs 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1404.9866 - val_loss: 1374.1202\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1402.2885 - val_loss: 1371.4767\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1399.5720 - val_loss: 1368.8872\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1396.9038 - val_loss: 1366.3032\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1394.2256 - val_loss: 1363.6736\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1391.5483 - val_loss: 1361.0706\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1388.8666 - val_loss: 1358.4928\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1386.1847 - val_loss: 1355.9430\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1383.5543 - val_loss: 1353.3087\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1380.8716 - val_loss: 1350.7925\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1378.2842 - val_loss: 1348.2288\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1375.6371 - val_loss: 1345.6741\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1372.9727 - val_loss: 1343.1232\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1370.3535 - val_loss: 1340.6272\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1367.7815 - val_loss: 1338.0779\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1365.1787 - val_loss: 1335.5635\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1362.5898 - val_loss: 1333.1279\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1360.0559 - val_loss: 1330.5870\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1357.4691 - val_loss: 1328.1165\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1354.9176 - val_loss: 1325.6667\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1352.3800 - val_loss: 1323.1696\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1349.8151 - val_loss: 1320.7426\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1347.3014 - val_loss: 1318.2549\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1344.7690 - val_loss: 1315.7968\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1342.2380 - val_loss: 1313.3936\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1339.7552 - val_loss: 1310.9761\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1337.2642 - val_loss: 1308.5769\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1334.8007 - val_loss: 1306.1281\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1332.2821 - val_loss: 1303.7998\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1329.8512 - val_loss: 1301.3593\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1327.3444 - val_loss: 1298.9747\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1324.8704 - val_loss: 1296.6660\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1322.4482 - val_loss: 1294.2635\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1320.0026 - val_loss: 1291.9252\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1317.5570 - val_loss: 1289.5739\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1315.1267 - val_loss: 1287.1960\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1312.7058 - val_loss: 1284.8141\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1310.2443 - val_loss: 1282.4442\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1307.8114 - val_loss: 1280.1500\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1305.4224 - val_loss: 1277.8632\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1303.0570 - val_loss: 1275.5023\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1300.6389 - val_loss: 1273.2147\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1298.2932 - val_loss: 1270.8678\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1295.8877 - val_loss: 1268.6283\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1293.5406 - val_loss: 1266.3252\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1291.1853 - val_loss: 1264.0470\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1288.8087 - val_loss: 1261.8503\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1286.4812 - val_loss: 1259.5426\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1284.1146 - val_loss: 1257.2756\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1281.7725 - val_loss: 1255.0110\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1279.4443 - val_loss: 1252.7234\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1277.1042 - val_loss: 1250.5089\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1274.8054 - val_loss: 1248.2490\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1272.4933 - val_loss: 1246.0452\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1270.1809 - val_loss: 1243.8403\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1267.8610 - val_loss: 1241.6541\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1265.6156 - val_loss: 1239.3812\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1263.3102 - val_loss: 1237.1692\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1261.0259 - val_loss: 1235.0048\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1258.7461 - val_loss: 1232.8311\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1256.4789 - val_loss: 1230.6525\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1254.2208 - val_loss: 1228.4525\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1251.9739 - val_loss: 1226.2842\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1249.7255 - val_loss: 1224.1320\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1247.4825 - val_loss: 1221.9679\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1245.2533 - val_loss: 1219.8567\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1243.0541 - val_loss: 1217.7050\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1240.8577 - val_loss: 1215.5618\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1238.6371 - val_loss: 1213.4097\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1236.4302 - val_loss: 1211.3191\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1234.2316 - val_loss: 1209.1846\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1232.0419 - val_loss: 1207.0708\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1229.8411 - val_loss: 1205.0251\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1227.7026 - val_loss: 1202.8987\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1225.5187 - val_loss: 1200.8571\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1223.3883 - val_loss: 1198.7433\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1221.1957 - val_loss: 1196.6774\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 1219.0526 - val_loss: 1194.5640\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1216.8859 - val_loss: 1192.5203\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1214.7433 - val_loss: 1190.4514\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1212.5920 - val_loss: 1188.4531\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1210.4805 - val_loss: 1186.3655\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1208.3381 - val_loss: 1184.3196\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1206.2223 - val_loss: 1182.2468\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1204.0902 - val_loss: 1180.2495\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1201.9835 - val_loss: 1178.1954\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1199.8719 - val_loss: 1176.1802\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1197.7952 - val_loss: 1174.1766\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1195.7098 - val_loss: 1172.2045\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1193.6333 - val_loss: 1170.1631\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1191.5504 - val_loss: 1168.1958\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1189.5071 - val_loss: 1166.2004\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1187.4412 - val_loss: 1164.2493\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1185.4044 - val_loss: 1162.2928\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1183.3304 - val_loss: 1160.3458\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1181.2825 - val_loss: 1158.3463\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1179.2152 - val_loss: 1156.3942\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1177.1670 - val_loss: 1154.4255\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1175.1461 - val_loss: 1152.4395\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1173.1174 - val_loss: 1150.4873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d4df30040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs= 100, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean squared errors = 1173.1174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## increase the number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =Sequential()\n",
    "model2.add(Dense(10, activation='relu', input_shape= (8,)))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "model2.add(Dense(10, activation='relu'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss ='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1652.1988 - val_loss: 1521.5925\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1511.6656 - val_loss: 1510.7251\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1484.8021 - val_loss: 1492.8956\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1447.8602 - val_loss: 1466.2662\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1410.6099 - val_loss: 1428.4811\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1486.6802 - val_loss: 1376.6389\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1394.3103 - val_loss: 1309.2308\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1318.8954 - val_loss: 1225.5012\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1224.1213 - val_loss: 1120.4568\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1049.1867 - val_loss: 997.1266\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 948.4826 - val_loss: 855.9651\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 802.6888 - val_loss: 710.8237\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 691.5433 - val_loss: 574.7920\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 527.2547 - val_loss: 461.1983\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 424.2374 - val_loss: 375.6004\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 319.7581 - val_loss: 318.6113\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 276.1430 - val_loss: 281.4729\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 212.1338 - val_loss: 259.0837\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 222.3412 - val_loss: 241.8278\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 199.4538 - val_loss: 229.1844\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 199.5188 - val_loss: 219.9612\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 193.1425 - val_loss: 212.4970\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 178.9568 - val_loss: 206.0279\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 176.1947 - val_loss: 200.3251\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 170.9072 - val_loss: 196.0484\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.0607 - val_loss: 191.4875\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 170.2211 - val_loss: 188.1196\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 162.5316 - val_loss: 185.5254\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 165.0323 - val_loss: 182.8918\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 155.1519 - val_loss: 180.6169\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.8327 - val_loss: 178.3824\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 151.7891 - val_loss: 176.5701\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 158.0959 - val_loss: 174.9305\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 164.0336 - val_loss: 173.2573\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 149.9719 - val_loss: 172.0193\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 149.8975 - val_loss: 170.4722\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.4126 - val_loss: 169.2063\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.8402 - val_loss: 168.6560\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.9826 - val_loss: 167.2666\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.8414 - val_loss: 166.1995\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.8593 - val_loss: 165.6615\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.6128 - val_loss: 164.8014\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 148.8005 - val_loss: 163.5846\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 136.4609 - val_loss: 162.5948\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 150.4460 - val_loss: 161.7852\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 135.0932 - val_loss: 161.3389\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 136.8005 - val_loss: 160.7346\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 136.7145 - val_loss: 159.4223\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.6061 - val_loss: 158.9875\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.6641 - val_loss: 158.1956\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.2123 - val_loss: 157.6469\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.7895 - val_loss: 156.7126\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9633 - val_loss: 156.2719\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 129.2278 - val_loss: 156.0163\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 133.3795 - val_loss: 155.2649\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.3179 - val_loss: 154.3462\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4153 - val_loss: 154.2099\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3876 - val_loss: 153.2493\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.2864 - val_loss: 152.6844\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.4758 - val_loss: 152.4489\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.8354 - val_loss: 151.7022\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.7162 - val_loss: 151.2081\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 123.1011 - val_loss: 150.8781\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 128.2793 - val_loss: 150.5807\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 122.6947 - val_loss: 149.6543\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 131.7787 - val_loss: 149.3159\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 123.7655 - val_loss: 149.3290\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.7133 - val_loss: 148.3338\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 130.9882 - val_loss: 148.0805\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 121.1343 - val_loss: 147.2367\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.4512 - val_loss: 146.7012\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 126.5406 - val_loss: 146.1754\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117.9153 - val_loss: 145.8291\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 123.7934 - val_loss: 145.0388\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.8690 - val_loss: 144.8453\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.3569 - val_loss: 144.3498\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 120.0992 - val_loss: 144.0238\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.6492 - val_loss: 143.4358\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 111.9729 - val_loss: 142.7082\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.5479 - val_loss: 142.5001\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.0282 - val_loss: 141.9796\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.7582 - val_loss: 141.5195\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117.9866 - val_loss: 141.3873\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.4135 - val_loss: 140.5704\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 120.3990 - val_loss: 140.1395\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.1311 - val_loss: 139.7851\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.8305 - val_loss: 139.8315\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 121.2660 - val_loss: 139.2061\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.8136 - val_loss: 138.7275\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.8168 - val_loss: 138.3553\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 104.1543 - val_loss: 137.9160\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.9190 - val_loss: 137.5491\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.5417 - val_loss: 137.1428\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.0267 - val_loss: 136.9432\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 112.9817 - val_loss: 136.6142\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.4198 - val_loss: 135.9058\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 120.8277 - val_loss: 135.9899\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 121.5940 - val_loss: 135.6066\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.2624 - val_loss: 135.0620\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 110.2116 - val_loss: 134.6633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d4df97a60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,Y_train, epochs= 100, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean squared errors = 110.2116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
